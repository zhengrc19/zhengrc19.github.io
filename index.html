<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <script async src="https://www.googletagmanager.com/gtag/js?id=G-B1VV1DJD2M"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-B1VV1DJD2M");</script> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Ray C. Zheng</title> <meta name="author" content="Ray C. Zheng"> <meta name="description" content=""> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://zhengrc19.github.io/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">About<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">Blog</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching</a> </li> <li class="nav-item "> <a class="nav-link" href="/learning/">Learning</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Ray</span> C. Zheng </h1> <p class="desc">Machine Learning Engineer, Google<br>Class of 2023, Department of CST, Tsinghua University</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/myself2-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/myself2-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/myself2-1400.webp"></source> <img src="/assets/img/myself2.jpeg" class="img-fluid z-depth-1 rounded" width="auto" height="auto" alt="myself2.jpeg" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="clearfix"> <p>Hi! I’m a Machine Learning Engineer at Google, located in the San Francisco Bay Area. Thank you for visiting my page!</p> <p>Before Google, I was a Data Scientist at the Powertrain Data team of <a href="https://lucidmotors.com/" rel="external nofollow noopener" target="_blank">Lucid Motors</a>. Prior to Lucid in Summer 2023, I obtained my bachelor’s degree as Outstanding Graduate (优秀毕业生) from the <a href="https://www.cs.tsinghua.edu.cn/" rel="external nofollow noopener" target="_blank">Department of Computer Science and Technology (CST)</a>, <a href="https://www.tsinghua.edu.cn/" rel="external nofollow noopener" target="_blank">Tsinghua University (THU)</a>.</p> <p>My research interests include robot and reinforcement learning, with publications listed <a href="publications">here</a>. I was fortunate to be advised by Prof. <a href="http://hxu.rocks" rel="external nofollow noopener" target="_blank">Huazhe Xu</a> at the <a href="https://iiis.tsinghua.edu.cn/en/" rel="external nofollow noopener" target="_blank">Institute for Interdisciplinary Information Sciences (IIIS)</a>, Tsinghua University. I try to look for problems in the real world which can be solved with artificial intelligence.</p> <p>My experiences cover both the industry and the academia, mainly in deep learning and software engineering. In Spring 2023, I was the teaching assistant of IIIS’s Deep Reinforcement Learning course. Prior to that, I was also the instructor/TA of 4 courses, listed <a href="teaching">here</a>. In Summer 2022, I was an Algorithm Engineer Intern at <a href="http://kuaishou.cn/" rel="external nofollow noopener" target="_blank">Kuaishou</a>, focusing on causal inference and discovery.</p> <p>I watch European football, specifically the <a href="https://www.premierleague.com/" rel="external nofollow noopener" target="_blank">English Premier League</a> and <a href="https://www.uefa.com/uefachampionsleague/" rel="external nofollow noopener" target="_blank">UEFA Champions League</a>. I have been a fan of <a href="https://www.mancity.com/" rel="external nofollow noopener" target="_blank">Manchester City FC</a> since 2013. My sports interests include football (both American and European), volleyball, and badminton. </p> </div> <p style="margin-bottom:1cm;"></p> <h2><a href="/news/" style="color: inherit;">News</a></h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row">Dec 2024</th> <td> I joined Google as Machine Learning Engineer. </td> </tr> <tr> <th scope="row">Nov 2024</th> <td> I got promoted at Lucid Motors from Data Scientist I to Data Scientist II. </td> </tr> <tr> <th scope="row">Aug 2023</th> <td> I joined Lucid Motors Powertrain Data team as Data Scientist. </td> </tr> <tr> <th scope="row">Jul 2023</th> <td> I was nominated and served as Reviewer for <a href="https://nips.cc/Conferences/2023/CallForDatasetsBenchmarks" rel="external nofollow noopener" target="_blank">NeurIPS 2023 Datasets and Benchmarks Track</a>. </td> </tr> <tr> <th scope="row">Jun 2023</th> <td> I graduated as Outstanding Graduate (优秀毕业生) from Department of CST, THU. </td> </tr> <tr> <th scope="row">Jan 2023</th> <td> Our paper “<a href="https://arxiv.org/abs/2303.03391" rel="external nofollow noopener" target="_blank">Decision Transformer under Random Frame Dropping</a>” is accepted to <a href="https://iclr.cc/Conferences/2023" rel="external nofollow noopener" target="_blank">ICLR 2023</a>. </td> </tr> <tr> <th scope="row">Jan 2023</th> <td> Our paper “<a href="https://sites.google.com/view/eil-website/" rel="external nofollow noopener" target="_blank">Extraneousness-Aware Imitation Learning</a>” is accepted to <a href="https://www.icra2023.org/" rel="external nofollow noopener" target="_blank">ICRA 2023</a>. </td> </tr> <tr> <th scope="row">Oct 2022</th> <td> Awarded scholarship in Academic Progress and Social Work from THU CST department. </td> </tr> <tr> <th scope="row">Aug 2022</th> <td> I finished my internship at <a href="http://kuaishou.cn/" rel="external nofollow noopener" target="_blank">Kuaishou</a> and won its “Best Practice Award”. </td> </tr> <tr> <th scope="row">Oct 2021</th> <td> Awarded scholarship in Tech Innovation and Sports Excellence from THU CST department. </td> </tr> </table> </div> </div> <p style="margin-bottom:1cm;"></p> <h2><a href="/publications/" style="color: inherit;">Publications</a></h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/bike-demand-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/bike-demand-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/bike-demand-1400.webp"></source> <img src="/assets/img/publication_preview/bike-demand.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="bike-demand.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="pan2019predicting" class="col-sm-8"> <div class="title">Predicting bike sharing demand using recurrent neural networks</div> <div class="author"> <a href="https://panyan7.github.io/" rel="external nofollow noopener" target="_blank">Yan Pan</a>, <em>Ray Chen Zheng</em>, Jiaxi Zhang, and <a href="https://scholar.google.com/citations?user=j1WaLpwAAAAJ" rel="external nofollow noopener" target="_blank">Xin Yao</a> </div> <div class="periodical"> <em>Procedia Computer Science</em>, 2019 </div> <div class="periodical"> 2018 International Conference on Identification, Information and Knowledge in the Internet of Things </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://www.sciencedirect.com/science/article/pii/S1877050919302364" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">HTML</a> <a href="https://www.sciencedirect.com/science/article/pii/S1877050919302364/pdf?md5=17d9747c4ced4e4bd10d4345573588e0&amp;pid=1-s2.0-S1877050919302364-main.pdf" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> <div class="badges"> <span class="altmetric-embed" data-doi="https://doi.org/10.1016/j.procs.2019.01.217" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-doi="https://doi.org/10.1016/j.procs.2019.01.217" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="abstract hidden"> <p>Predicting bike sharing demand can help bike sharing companies to allocate bikes better and ensure a more sufficient circulation of bikes for customers. This paper proposes a real-time method for predicting bike renting and returning in different areas of a city during a future period based on historical data, weather data, and time data. We construct a network of bike trips from the data, use a community detection method on the network, and find two communities with the most demand for shared bikes. We use data of stations in the two communities as our dataset, and train an deep LSTM model with two layers to predict bike renting and returning, making use of the gating mechanism of long short term memory and the ability to process sequence data of recurrent neural network. We evaluate the model with the Root Mean Squared Error of data and show that the prediction of proposed model outperforms that of other deep learning models by comparing their RMSEs.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">pan2019predicting</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Predicting bike sharing demand using recurrent neural networks}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Procedia Computer Science}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{147}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{562-566}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">note</span> <span class="p">=</span> <span class="s">{2018 International Conference on Identification, Information and Knowledge in the Internet of Things}</span><span class="p">,</span>
  <span class="na">issn</span> <span class="p">=</span> <span class="s">{1877-0509}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{https://doi.org/10.1016/j.procs.2019.01.217}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://www.sciencedirect.com/science/article/pii/S1877050919302364}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Pan, Yan and Zheng, Ray Chen and Zhang, Jiaxi and Yao, Xin}</span><span class="p">,</span>
  <span class="na">keywords</span> <span class="p">=</span> <span class="s">{Shared bike demand prediction, time series forecasting, recurrent neural networks, long short term memory}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/eil.gif-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/eil.gif-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/eil.gif-1400.webp"></source> <img src="/assets/img/publication_preview/eil.gif" class="preview z-depth-1 rounded" width="auto" height="auto" alt="eil.gif" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="zheng2022extraneous" class="col-sm-8"> <div class="title">Extraneousness-Aware Imitation Learning</div> <div class="author"> <em>Ray Chen Zheng*</em>, <a href="https://hukz18.github.io/" rel="external nofollow noopener" target="_blank">Kaizhe Hu*</a>, <a href="https://gemcollector.github.io/" rel="external nofollow noopener" target="_blank">Zhecheng Yuan</a>, <a href="https://people.csail.mit.edu/boyuanc/" rel="external nofollow noopener" target="_blank">Boyuan Chen</a>, and <a href="http://hxu.rocks" rel="external nofollow noopener" target="_blank">Huazhe Xu</a> </div> <div class="periodical"> <em>In IEEE International Conference on Robotics and Automation (ICRA)</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2210.01379" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/zhengrc19/eil-code" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://sites.google.com/view/eil-website/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="badges"> <span class="altmetric-embed" data-doi="10.1109/ICRA48891.2023.10161521" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-doi="10.1109/ICRA48891.2023.10161521" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="abstract hidden"> <p>Visual imitation learning provides an effective framework to learn skills from demonstrations. However, the quality of the provided demonstrations usually significantly affects the ability of an agent to acquire desired skills. There- fore, the standard visual imitation learning assumes near- optimal demonstrations, which are expensive or sometimes prohibitive to collect. Previous works propose to learn from noisy demonstrations; however, the noise is usually assumed to follow a context-independent distribution such as a uniform or gaussian distribution. In this paper, we consider another crucial yet underexplored setting — imitation learning with task- irrelevant yet locally consistent segments in the demonstrations (e.g., wiping sweat while cutting potatoes in a cooking tutorial). We argue that such noise is common in real world data and term them as “extraneous” segments. To tackle this problem, we introduce Extraneousness-Aware Imitation Learning (EIL), a self-supervised approach that learns visuomotor policies from third-person demonstrations with extraneous subsequences. EIL learns action-conditioned observation embeddings in a self-supervised manner and retrieves task-relevant observations across visual demonstrations while excluding the extraneous ones. Experimental results show that EIL outperforms strong baselines and achieves comparable policies to those trained with perfect demonstration on both simulated and real-world robot control tasks. The project page can be found here: https://sites.google.com/view/eil-website.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zheng2022extraneous</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Extraneousness-Aware Imitation Learning}}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{{IEEE International Conference on Robotics and Automation (ICRA)}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zheng*, Ray Chen and Hu*, Kaizhe and Yuan, Zhecheng and Chen, Boyuan and Xu, Huazhe}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{2973-2979}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.1109/ICRA48891.2023.10161521}</span><span class="p">,</span>
  <span class="na">langid</span> <span class="p">=</span> <span class="s">{english}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 preview"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/publication_preview/defog-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/publication_preview/defog-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/publication_preview/defog-1400.webp"></source> <img src="/assets/img/publication_preview/defog.png" class="preview z-depth-1 rounded" width="auto" height="auto" alt="defog.png" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div id="hu2023decision" class="col-sm-8"> <div class="title">Decision Transformer under Random Frame Dropping</div> <div class="author"> <a href="https://hukz18.github.io/" rel="external nofollow noopener" target="_blank">Kaizhe Hu*</a>, <em>Ray Chen Zheng*</em>, <a href="http://people.iiis.tsinghua.edu.cn/~gaoyang/yang-gao.weebly.com/index.html" rel="external nofollow noopener" target="_blank">Yang Gao</a>, and <a href="http://hxu.rocks" rel="external nofollow noopener" target="_blank">Huazhe Xu</a> </div> <div class="periodical"> <em>In The Eleventh International Conference on Learning Representations</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a href="http://arxiv.org/abs/2303.03391" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">arXiv</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/hukz18/DeFog" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="badges"> <span class="altmetric-embed" data-altmetric-id="" data-hide-no-mentions="true" data-hide-less-than="15" data-badge-type="2" data-badge-popover="right"></span> <span class="__dimensions_badge_embed__" data-pmid="" data-hide-zero-citations="true" data-style="small_rectangle" data-legend="hover-right" style="margin-bottom: 6px;"></span> </div> <div class="abstract hidden"> <p>Controlling agents remotely with deep reinforcement learning (DRL) in the real world is yet to come. One crucial stepping stone is to devise RL algorithms that are robust in the face of dropped information from corrupted communication or malfunctioning sensors. Typical RL methods usually require considerable online interaction data that are costly and unsafe to collect in the real world. Furthermore, when applying to the frame dropping scenarios, they perform unsatisfactorily even with moderate drop rates. To address these issues, we propose Decision Transformer under Random Frame Dropping (DeFog), an offline RL algorithm that enables agents to act robustly in frame dropping scenarios without online interaction. DeFog first randomly masks out data in the offline datasets and explicitly adds the time span of frame dropping as inputs. After that, a finetuning stage on the same offline dataset with a higher mask rate would further boost the performance. Empirical results show that DeFog outperforms strong baselines under severe frame drop rates like 90%, while maintaining similar returns under non-frame-dropping conditions in the regular MuJoCo control benchmarks and the Atari environments. Our approach offers a robust and deployable solution for controlling agents in real-world environments with limited or unreliable data.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">hu2023decision</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{Decision Transformer under Random Frame Dropping}}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Hu*, Kaizhe and Zheng*, Ray Chen and Gao, Yang and Xu, Huazhe}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{{The Eleventh International Conference on Learning Representations}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">url</span> <span class="p">=</span> <span class="s">{https://openreview.net/forum?id=NmZXv4467ai}</span><span class="p">,</span>
  <span class="na">langid</span> <span class="p">=</span> <span class="s">{english}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <p style="margin-bottom:1cm;"></p> <div class="social"> <div class="contact-icons"> <a href="mailto:%72%61%79%63%68%65%6E%7A%68%65%6E%67@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fas fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=gwUGHwsAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/zhengrc19" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fab fa-github"></i></a> <a href="https://www.linkedin.com/in/ray-zheng-366053132" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fab fa-linkedin"></i></a> <a href="https://twitter.com/zhengrc19" title="Twitter" rel="external nofollow noopener" target="_blank"><i class="fab fa-twitter"></i></a> <a href="https://dblp.org/pid/235/8101.html" title="DBLP" rel="external nofollow noopener" target="_blank"><i class="ai ai-dblp"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fas fa-rss-square"></i></a> </div> <div class="contact-note"> </div> </div> </article> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2024 Ray C. Zheng. Last updated: December 23, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>